{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "dT8fL1A7JXmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is a parameter?\n",
        " - In the context of Machine Learning models, parameters are values that the model learns from the training data during the training process. These parameters define the model's behavior and allow it to make predictions or classifications on new data."
      ],
      "metadata": {
        "id": "NixWtrMrJhml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is correlation? What does negative correlation mean?\n",
        " - Correlation is a statistical measure that describes the extent to which two variables change together.\n",
        " - A **negative correlation** means that as one variable increases, the other variable tends to decrease."
      ],
      "metadata": {
        "id": "wVPVz7d4JpTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Define Machine Learning. What are the main components in Machine Learning?\n",
        " - Machine Learning is a field of artificial intelligence where systems learn from data, identify patterns, and make decisions with minimal human intervention. The main components typically include:\n",
        "     - **Data**: The raw material for training.\n",
        "     - **Model**: The algorithm that learns from the data.\n",
        "     - **Learning Algorithm**: The method used to train the model on the data (e.g., gradient descent).\n",
        "     - **Evaluation Metric**: A measure to assess the performance of the trained model."
      ],
      "metadata": {
        "id": "ECqqRePZJ4Wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        " - The loss value quantifies the difference between the model's predictions and the actual values in the training data. A lower loss value generally indicates that the model's predictions are closer to the true values, suggesting a better-performing model. The goal during training is to minimize the loss."
      ],
      "metadata": {
        "id": "boEg1mTIKR6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What are continuous and categorical variables?\n",
        " - **Continuous variables**: Variables that can take on any value within a given range (e.g., temperature, height, price).\n",
        " - **Categorical variables**: Variables that can take on a limited number of distinct values, often representing categories or groups (e.g., color, gender, country)."
      ],
      "metadata": {
        "id": "9MmLVnixKa9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        " - Machine Learning algorithms typically require numerical input. Categorical variables need to be converted into a numerical format. Common techniques include:\n",
        "     - **One-Hot Encoding**: Creates binary columns for each category, where a '1' indicates the presence of that category and '0' otherwise.\n",
        "     - **Label Encoding**: Assigns a unique integer to each category. This can be problematic for nominal categorical variables as it introduces an artificial order."
      ],
      "metadata": {
        "id": "J50OWljhKndu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What do you mean by training and testing a dataset?\n",
        " - **Training**: The process of using a portion of the dataset (the training set) to teach the Machine Learning model to learn patterns and relationships in the data.\n",
        " - **Testing**: The process of evaluating the performance of the trained model on a separate, unseen portion of the dataset (the testing set). This helps to assess how well the model generalizes to new data."
      ],
      "metadata": {
        "id": "jOMkM3ELK3Nm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is sklearn.preprocessing?\n",
        " - sklearn.preprocessing is a module in the scikit-learn library that provides a collection of functions and classes to preprocess data before training a Machine Learning model. This includes tasks like scaling, encoding categorical features, and handling missing values."
      ],
      "metadata": {
        "id": "6u0nNNbuLBuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is a Test set?\n",
        "- A test set is a portion of the dataset that is held back during the training process and is used only for evaluating the performance of the trained model. It provides an unbiased estimate of how well the model will perform on new, unseen data."
      ],
      "metadata": {
        "id": "UFozVvfaLG-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        " - You can split data using train_test_split from sklearn.model_selection."
      ],
      "metadata": {
        "id": "hafNRmNLLOL1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTTTGp4LH7bE",
        "outputId": "575e9027-19d1-4786-80e0-c9a6b38f9ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The variable 'data' is not defined.\n",
            "Please load your data into a pandas DataFrame named 'data' before proceeding.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a pandas DataFrame called 'data' and a target variable 'target'\n",
        "# Note: The variable 'data' is not defined in the provided context.\n",
        "# You will need to load your data into a pandas DataFrame named 'data' before running this code.\n",
        "# Example: data = pd.read_csv('your_data.csv')\n",
        "# Also, make sure your DataFrame has a column named 'target'.\n",
        "try:\n",
        "    X = data.drop('target', axis=1) # Features\n",
        "    y = data['target'] # Target variable\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # X_train: training features\n",
        "    # X_test: testing features\n",
        "    # y_train: training target\n",
        "    # y_test: testing target\n",
        "    # test_size: the proportion of the dataset to include in the test split (here 20%)\n",
        "    # random_state: ensures the split is the same each time you run the code\n",
        "\n",
        "except NameError:\n",
        "    print(\"Error: The variable 'data' is not defined.\")\n",
        "    print(\"Please load your data into a pandas DataFrame named 'data' before proceeding.\")\n",
        "except KeyError:\n",
        "    print(\"Error: The DataFrame 'data' does not contain a column named 'target'.\")\n",
        "    print(\"Please ensure your target variable column is named 'target' or update the code accordingly.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common approach to a Machine Learning problem involves these steps:\n",
        "*   **Understand the problem:** Clearly define the goal and the type of problem (e.g., classification, regression).\n",
        "*   **Data Collection:** Gather relevant data.\n",
        "*   **Data Cleaning and Preprocessing:** Handle missing values, outliers, and transform data as needed (e.g., encoding categorical variables, scaling).\n",
        "*   **Exploratory Data Analysis (EDA):** Analyze and visualize the data to understand its characteristics and relationships.\n",
        "*   **Feature Engineering:** Create new features from existing ones if necessary.\n",
        "*   **Model Selection:** Choose an appropriate Machine Learning model based on the problem type and data characteristics.\n",
        "*   **Model Training:** Train the selected model on the training data.\n",
        "*   **Model Evaluation:** Assess the model's performance using appropriate metrics on the testing data.\n",
        "*   **Hyperparameter Tuning:** Optimize the model's parameters to improve performance.\n",
        "*   **Deployment:** Put the trained model into production."
      ],
      "metadata": {
        "id": "w01ClLqIMF12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        " - EDA is crucial because it helps you:\n",
        "\n",
        "     - Understand the structure and distribution of your data.\n",
        "     - Identify missing values, outliers, and errors.\n",
        "     - Discover relationships and correlations between variables.\n",
        "     - Gain insights that can inform feature engineering and model selection.\n",
        "     - Visualize the data to communicate findings effectively."
      ],
      "metadata": {
        "id": "GvAii6XBMJvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.What is correlation?\n",
        " - Correlation is a statistical measure that describes the extent to which two variables change together."
      ],
      "metadata": {
        "id": "PxYxGc4jMYF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.What does negative correlation mean?\n",
        " - A negative correlation means that as one variable increases, the other variable tends to decrease."
      ],
      "metadata": {
        "id": "XgMSzLgEMgUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. How can you find correlation between variables in Python?\n",
        "- You can use the .corr() method on a pandas DataFrame."
      ],
      "metadata": {
        "id": "LaydJWWUMpD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'col1': np.random.rand(10),\n",
        "        'col2': np.random.rand(10),\n",
        "        'col3': np.random.rand(10)}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3676mDItM7VP",
        "outputId": "cfda4ff9-dae3-4df8-a9da-ca2a58532161"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          col1      col2      col3\n",
            "col1  1.000000  0.199766 -0.260357\n",
            "col2  0.199766  1.000000  0.639237\n",
            "col3 -0.260357  0.639237  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What is causation? Explain difference between correlation and causation with an example.\n",
        "  - **Causation:** Means that one event is the direct result of another event. A change in one variable directly causes a change in another.\n",
        "  - **Correlation:** Indicates that two variables are related and change together, but it doesn't imply that one causes the other.\n",
        "- Example :\n",
        "   - **Correlation:** There might be a correlation between ice cream sales and the number of drownings in a given month. Both tend to increase in the summer.\n",
        "   - **Causation:** Eating ice cream does not cause drowning. The common factor is the hot weather, which leads to both more ice cream consumption and more swimming (and thus potentially more drownings). This illustrates that correlation does not equal causation."
      ],
      "metadata": {
        "id": "c-qdN9UUM9-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        " - An optimizer is an algorithm used to minimize the loss function during the training of a Machine Learning model. It adjusts the model's parameters iteratively to reduce the error between predictions and actual values.\n",
        "\n",
        "Different types of optimizers include:\n",
        " - **Gradient Descent (and its variants like Stochastic Gradient Descent - SGD, Mini-Batch Gradient Descent):**\n",
        "     - **Explanation:** It calculates the gradient (the direction of steepest ascent) of the loss function with respect to the model's parameters and updates the parameters in the opposite direction of the gradient to move towards the minimum of the loss function.\n",
        "     - **Example (SGD):** In each iteration, SGD uses a single random training example to calculate the gradient and update the parameters. This makes it faster for large datasets but can lead to noisy updates.\n",
        " - **Adam:**\n",
        "     - **Explanation:** Adam (Adaptive Moment Estimation) is an adaptive learning rate optimization algorithm that computes adaptive learning rates for each parameter. It combines the advantages of two other extensions of SGD: AdaGrad and RMSProp.\n",
        "     - **Example:** Widely used in deep learning due to its efficiency and effectiveness. It's often a good default choice."
      ],
      "metadata": {
        "id": "jk8meAMPNrUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. What is sklearn.linear_model ?\n",
        " - sklearn.linear_model is a module in scikit-learn that contains various linear models for classification and regression. This includes algorithms like Linear Regression, Logistic Regression, Ridge, Lasso, and Elastic Net.\n",
        "\n"
      ],
      "metadata": {
        "id": "qxbtClRIOfS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.What does model.fit() do? What arguments must be given?\n",
        " - The model.fit() method is used to train a Machine Learning model on the provided data. It learns the patterns and relationships from the training data to build the model.\n",
        "\n",
        " - The essential arguments typically required are:\n",
        "     - X: The training data (features). This is usually a 2D array-like structure (e.g., a NumPy array or pandas DataFrame) where each row represents a sample and each column represents a feature.\n",
        "     - y: The target variable for the training data. This is usually a 1D array-like structure containing the corresponding labels or values for each sample in X."
      ],
      "metadata": {
        "id": "h-ekkAfqOnFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with a Linear Regression model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "# Assuming X_train and y_train are your training data\n",
        "# Note: X_train and y_train were not defined in the provided context before this cell.\n",
        "# You will need to run the cell where train_test_split is used to create these variables.\n",
        "try:\n",
        "    model.fit(X_train, y_train)\n",
        "except NameError:\n",
        "    print(\"Error: X_train or y_train are not defined.\")\n",
        "    print(\"Please ensure you have run the data splitting cell first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pCWAY-aPGXR",
        "outputId": "29957596-7919-461a-b0e8-80f2912fdee9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: X_train or y_train are not defined.\n",
            "Please ensure you have run the data splitting cell first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.What does model.predict() do? What arguments must be given?\n",
        " - The model.predict() method is used to make predictions using a trained Machine Learning model. It takes new input data and outputs the model's predictions based on what it learned during training.\n",
        "\n",
        "The essential argument required is:\n",
        "     - X: The input data for which you want to make predictions. This should have the same number of features as the data used to train the model."
      ],
      "metadata": {
        "id": "0d43y8ybPPdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a trained model and X_test is your testing data\n",
        "    predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "THRtvoj6PHRU",
        "outputId": "17956170-2391-4eb0-cb59-64dcd7716f41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-8-43f2ee5f3049>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-43f2ee5f3049>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    predictions = model.predict(X_test)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.What are continuous and categorical variables?\n",
        " - **Continuous variables:** Variables that can take on any value within a given range (e.g., temperature, height, price).\n",
        " - **Categorical variables:** Variables that can take on a limited number of distinct values, often representing categories or groups (e.g., color, gender, country)."
      ],
      "metadata": {
        "id": "WQcx4zUdPjRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        " - Feature scaling is a technique used to standardize or normalize the range of independent variables (features) in a dataset.\n",
        "\n",
        " - It helps in Machine Learning by :\n",
        "    - **Improving the performance of algorithms sensitive to feature scales:**\n",
        "    Many algorithms (like gradient descent-based methods, support vector machines, and k-nearest neighbors) perform better when features are on a similar scale. Large differences in scales can cause features with larger values to dominate the learning process.\n",
        "    - **Speeding up convergence:** For iterative algorithms like gradient descent, scaling can help the optimization process converge faster."
      ],
      "metadata": {
        "id": "EFb3-yhiPyMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.How do we perform scaling in Python?\n",
        " - You can use various scalers from sklearn.preprocessing. Two common ones are StandardScaler and MinMaxScaler."
      ],
      "metadata": {
        "id": "5XjOIcVnQokp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Create a sample DataFrame\n",
        "    data = {'feature1': np.random.rand(10) * 100,\n",
        "            'feature2': np.random.rand(10) * 0.1}\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Using StandardScaler (scales data to have a mean of 0 and standard deviation of 1)\n",
        "    scaler_std = StandardScaler()\n",
        "    df_scaled_std = scaler_std.fit_transform(df)\n",
        "    df_scaled_std = pd.DataFrame(df_scaled_std, columns=df.columns) # Convert back to DataFrame\n",
        "\n",
        "    print(\"Scaled with StandardScaler:\")\n",
        "    print(df_scaled_std)\n",
        "\n",
        "    # Using MinMaxScaler (scales data to a specified range, typically [0, 1])\n",
        "    scaler_minmax = MinMaxScaler()\n",
        "    df_scaled_minmax = scaler_minmax.fit_transform(df)\n",
        "    df_scaled_minmax = pd.DataFrame(df_scaled_minmax, columns=df.columns) # Convert back to DataFrame\n",
        "\n",
        "    print(\"\\nScaled with MinMaxScaler:\")\n",
        "    print(df_scaled_minmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "MPjQcVf6PbaC",
        "outputId": "de015c5f-480c-4f16-8ab5-24c8bf32169f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-9-eb1e532f9dc7>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-eb1e532f9dc7>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import pandas as pd\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is sklearn.preprocessing?\n",
        " - sklearn.preprocessing is a module in the scikit-learn library that provides a collection of functions and classes to preprocess data before training a Machine Learning model. This includes tasks like scaling, encoding categorical features, and handling missing values."
      ],
      "metadata": {
        "id": "IM0s37mcQzUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.How do we split data for model fitting (training and testing) in Python?\n",
        " - You can split data using train_test_split from sklearn.model_selection."
      ],
      "metadata": {
        "id": "Hn6BbkitQ-Sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a pandas DataFrame called 'data' and a target variable 'target'\n",
        "# Note: The variable 'data' is not defined in the provided context.\n",
        "# You will need to load your data into a pandas DataFrame named 'data' before running this code.\n",
        "# Example: data = pd.read_csv('your_data.csv')\n",
        "# Also, make sure your DataFrame has a column named 'target'.\n",
        "try:\n",
        "    X = data.drop('target', axis=1) # Features\n",
        "    y = data['target'] # Target variable\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # X_train: training features\n",
        "    # X_test: testing features\n",
        "    # y_train: training target\n",
        "    # y_test: testing target\n",
        "    # test_size: the proportion of the dataset to include in the test split (here 20%)\n",
        "    # random_state: ensures the split is the same each time you run the code\n",
        "\n",
        "except NameError:\n",
        "    print(\"Error: The variable 'data' is not defined.\")\n",
        "    print(\"Please load your data into a pandas DataFrame named 'data' before proceeding.\")\n",
        "except KeyError:\n",
        "    print(\"Error: The DataFrame 'data' does not contain a column named 'target'.\")\n",
        "    print(\"Please ensure your target variable column is named 'target' or update the code accordingly.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cwrgIDuaQx9n",
        "outputId": "f5c22448-6c0c-4829-cde8-c10b2ffd0546"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'drop'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d1892112d4aa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Also, make sure your DataFrame has a column named 'target'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'drop'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common approach to a Machine Learning problem involves these steps:\n",
        "*   **Understand the problem:** Clearly define the goal and the type of problem (e.g., classification, regression).\n",
        "*   **Data Collection:** Gather relevant data.\n",
        "*   **Data Cleaning and Preprocessing:** Handle missing values, outliers, and transform data as needed (e.g., encoding categorical variables, scaling).\n",
        "*   **Exploratory Data Analysis (EDA):** Analyze and visualize the data to understand its characteristics and relationships.\n",
        "*   **Feature Engineering:** Create new features from existing ones if necessary.\n",
        "*   **Model Selection:** Choose an appropriate Machine Learning model based on the problem type and data characteristics.\n",
        "*   **Model Training:** Train the selected model on the training data.\n",
        "*   **Model Evaluation:** Assess the model's performance using appropriate metrics on the testing data.\n",
        "*   **Hyperparameter Tuning:** Optimize the model's parameters to improve performance.\n",
        "*   **Deployment:** Put the trained model into production."
      ],
      "metadata": {
        "id": "VDkullMJRUrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        " - Data encoding is the process of converting data from one format to another. In the context of Machine Learning, it most commonly refers to converting categorical data into a numerical format that algorithms can understand and process. This is necessary because most Machine Learning algorithms work with numerical inputs. Common encoding techniques are One-Hot Encoding and Label Encoding (as explained in question 6)."
      ],
      "metadata": {
        "id": "Wf8d00tMRmC4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0wWLOc0RQuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}